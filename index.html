<!DOCTYPE html>
<!-- saved from url=(0039)http://cs.stanford.edu/people/karpathy/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Andrej Karpathy Academic Website</title>
  <link href="./Andrej Karpathy Academic Website_files/bootstrap.min.css" rel="stylesheet" media="screen">
  <link href="./Andrej Karpathy Academic Website_files/style.css" rel="stylesheet">
  <link href="./Andrej Karpathy Academic Website_files/css" rel="stylesheet" type="text/css">


<!-- Tracking code -->
<script type="text/javascript" async="" src="./Andrej Karpathy Academic Website_files/ga.js"></script><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-3698471-13']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body onload="start()">

<div id="header" class="bg1">
  <div id="topnav">
    <ul>
      <li><a href="http://karpathy.github.io/">blog</a></li>
    </ul>
  </div>
  <div id="headerblob">
    <img src="img/me2.jpg" class="img-circle imgme">
    <div id="headertext">
      <div id="htname">Andrej Karpathy</div>
      <div id="htdesc">Stanford Computer Science Ph.D. student</div>
      <div id="htem">karpathy _at_ cs.stanford.edu</div>
      <div id="icons">
        <div class="svgico">
          <a href="https://twitter.com/karpathy"><img src="./Andrej Karpathy Academic Website_files/03-twitter.svg"></a>
        </div>
        <div class="svgico">
          <a href="https://karpathy.github.io/"><img src="./Andrej Karpathy Academic Website_files/20-rss.svg"></a>
        </div>
        <div class="svgico">
          <a href="https://github.com/karpathy"><img src="./Andrej Karpathy Academic Website_files/octocat.svg" width="56px"></a>
        </div>
      </div>
    </div>
  </div>
</div>

<!-- <div class="container">
  <div id="timeline">
    <div class="timelineitem">
      <div class="tdate">2016 -</div>
      <div class="ttitle">Research Scientist at <a href="http://www.wired.com/2016/04/openai-elon-musk-sam-altman-plan-to-set-artificial-intelligence-free/" target="_blank">OpenAI</a></div>
      <div class="tdesc">Deep Learning, Generative Models, Reinforcement Learning</div>
    </div>
    <div class="timelineitem">
      <div class="tdate">Summer 2015</div>
      <div class="ttitle">DeepMind Internship</div>
      <div class="tdesc">Deep Reinforcement Learning group</div>
    </div>
    <div class="timelineitem">
      <div class="tdate">Summer 2013</div>
      <div class="ttitle">Google Research Internship</div>
      <div class="tdesc">Large-Scale Supervised Deep Learning for Videos.</div>
    </div>
    <div class="timelineitem">
      <div class="tdate">2011 - 2015</div>
      <div class="ttitle">Stanford Computer Science Ph.D. student</div>
      <div class="tdesc">Deep Learning, Computer Vision, Natural Language Processing. My adviser was <a href="http://vision.stanford.edu/">Fei-Fei Li.</a></div>
    </div>
    <div class="timelineitem">
      <div class="tdate">Summer 2011</div>
      <div class="ttitle">Google Research Internship</div>
      <div class="tdesc">Large-Scale Unsupervised Deep Learning for Videos.</div>
    </div>
    <div class="timelineitem">
     <div class="tdate">2009-2011</div>
      <div class="ttitle">University of British Columbia: Master's Degree</div>
      <div class="tdesc">I worked with <a href="https://www.cs.ubc.ca/~van/">Michiel van de Panne</a> on learning Compositional Controllers for Physically-simulated Articulate Figures.</div>
    </div>
    <div class="timelineitem">
      <div class="tdate">2005-2009
      </div>
      <div class="ttitle">University of Toronto: Bachelor's Degree</div>
      <div class="tdesc">Double major in Computer Science and Physics.</div>
    </div>
  </div>
</div> -->

<div class="container" style="font-size:18px; font-weight:300;margin-top:50px;margin-bottom:50px;">
  <b>Bio</b>. I am a Research Scientist at <a href="http://openai.com/">OpenAI</a> working on Deep Learning in Computer Vision, Generative Modeling and Reinforcement Learning. Previously I was a Computer Science PhD student at Stanford, working with <a href="http://vision.stanford.edu/">Fei-Fei Li</a> on Convolutional/Recurrent Neural Network architectures and their applications in Computer Vision, Natural Language Processing and their intersection. Over the course of my PhD I squeezed in two internships at Google where I worked on large-scale feature learning over YouTube videos, and in 2015 I interned at DeepMind and worked on Deep Reinforcement Learning. Together with Fei-Fei, I designed and taught a new Stanford class on <a href="http://cs231n.stanford.edu/">Convolutional Neural Networks for Visual Recognition (CS231n)</a>. The class was the first Deep Learning course offering at Stanford and has grown from 150 enrolled in 2015 to 330 students in 2016, and <a href="https://twitter.com/karpathy/status/849338608297406465">750 students in 2017</a>.

  <br><br>
  On a side for fun I <a href="http://karpathy.github.io/">blog</a>, <a href="https://twitter.com/karpathy">tweet</a>, and maintain several Deep Learning libraries written in Javascript (e.g. <a href="http://convnetjs.com/">ConvNetJS</a>, <a href="http://cs.stanford.edu/people/karpathy/recurrentjs/">RecurrentJS</a>, <a href="http://cs.stanford.edu/people/karpathy/reinforcejs/">REINFORCEjs</a>, <a href="http://cs.stanford.edu/people/karpathy/tsnejs/">t-sneJS</a>). I am also sometimes jokingly referred to as <i>the</i> reference human for ImageNet (<a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">post</a> :)). I also recently expanded on this with <a href="http://www.arxiv-sanity.com/">arxiv-sanity.com</a>, which lets you search and sort through ~30,000 Arxiv papers on Machine Learning over the last 3 years in the same pretty format.

  <br><br>
  <b>Timeline</b>.
  <br>
  <span class="t2when">2016 - now:</span>
  <span class="t2who">Research Scientist at <a href="http://www.wired.com/2016/04/openai-elon-musk-sam-altman-plan-to-set-artificial-intelligence-free/" target="_blank">OpenAI</a></span>
  <span class="t2what">Deep Learning, Generative Models, Reinforcement Learning</span>

  <br>
  <span class="t2when">Summer 2015:</span>
  <span class="t2who">DeepMind Internship</span>
  <span class="t2what">Deep Reinforcement Learning group</span>

  <br>
  <span class="t2when">Summer 2013:</span>
  <span class="t2who">Google Research Internship</span>
  <span class="t2what">Large-Scale Supervised Deep Learning for Videos</span>

  <br>
  <span class="t2when">2011 - 2015:</span>
  <span class="t2who">Stanford Computer Science Ph.D. student</span>
  <span class="t2what">Deep Learning, Computer Vision, Natural Language Processing. Adviser: <a href="http://vision.stanford.edu/">Fei-Fei Li.</a></span>

  <br>
  <span class="t2when">Summer 2011:</span>
  <span class="t2who">Google Research Internship</span>
  <span class="t2what">Large-Scale Unsupervised Deep Learning for Videos</span>

  <br>
  <span class="t2when">2009-2011:</span>
  <span class="t2who">University of British Columbia: Master's Degree</span>
  <span class="t2what">Learning Compositional Controllers for Physically-simulated Articulate Figures. Adviser: <a href="https://www.cs.ubc.ca/~van/">Michiel van de Panne</a></span>

  <br>
  <span class="t2when">2005-2009:</span>
  <span class="t2who">University of Toronto: Bachelor's Degree</span>
  <span class="t2what">Double major in Computer Science and Physics</span>

  <br><br>
  <b>News</b>.
  <br>Feb 2017: Joined the steering committee of <a href="http://distill.pub/about/">distill.pub</a>!
  <br>Dec 2016: Started a <a href="https://medium.com/@karpathy">Medium blog</a> for smaller/shorter blog posts, in addition to my <a href="https://karpathy.github.io/">usual one</a>.

</div>

<hr class="soft">

<div class="container">
  <h2>Publications</h2>
  <div id="pubs">
	 
   <div class="pubwrap">
      <div class="pubd" style="display:inline-block"><a href="https://openreview.net/pdf?id=BJrFC6ceg">[PDF]</a> PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications, </div>
      <div class="puba" style="display:inline-block">Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma, and Yaroslav Bulatov</div>
      <div class="pubv" style="display:inline-block">2017</div>
    </div>

		<div class="pubwrap">
			<img src="./Andrej Karpathy Academic Website_files/thesis.jpg" style="width:100%">
			<div class="pubd" style="display:inline-block"><a href="http://cs.stanford.edu/people/karpathy/main.pdf">[PDF]</a> Connecting Images and Natural Language, </div>
			<div class="puba" style="display:inline-block">Andrej Karpathy, </div>
			<div class="pubv" style="display:inline-block">PhD Thesis, 2016</div>
		</div>

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./Andrej Karpathy Academic Website_files/densecap.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">DenseCap: Fully Convolutional Localization Networks for Dense Captioning</div>
            <div class="pubd">Efficiently identify and caption all the things in an image with a single forward pass of a network. Our model is fully differentiable and trained end-to-end without any pipelines. The model is also very efficient (processes a 720x600 image in only 240ms), and evaluation on a large-scale dataset of 94,000 images and 4,100,000 region captions shows that it outperforms baselines based on previous approaches.</div>
            <div class="puba">Justin Johnson*, Andrej Karpathy*, Li Fei-Fei</div>
            <div class="pubv">CVPR 2016 (Oral)</div>
            <div class="publ">
              <ul>
                <li><a href="http://cs.stanford.edu/people/karpathy/densecap">Project</a></li>
                <li><a href="http://cs.stanford.edu/people/karpathy/densecap.pdf">PDF</a></li>
                <li><a href="https://github.com/jcjohnson/densecap">Code (Github)</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
      <div class="row">
        <img src="./Andrej Karpathy Academic Website_files/densecap_more.jpg" style="max-width:100%; margin-top:30px;">
      </div>
    </div>

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./Andrej Karpathy Academic Website_files/icon.jpg">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Visualizing and Understanding Recurrent Networks</div>
            <div class="pubd">We study both qualitatively and quantitatively
              the performance improvements of Recurrent Networks in Language Modeling tasks compared to finite-horizon models. Our analysis sheds light on the source of improvements
              , and identifies areas for further potential gains. Among some fun results we find LSTM cells that keep track of long-range dependencies such as line lengths, quotes and brackets.</div>
            <div class="puba">Andrej Karpathy*, Justin Johnson*, Li Fei-Fei</div>
            <div class="pubv">ICLR 2016 Workshop</div>
            <div class="publ">
              <ul>
                <li><a href="http://arxiv.org/abs/1506.02078">PDF</a></li>
								<li><a href="http://github.com/karpathy/char-rnn">Code (char-rnn)</a></li>
								<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Blog Post</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    

      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
          <img src="./Andrej Karpathy Academic Website_files/rnn7.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Deep Visual-Semantic Alignments for Generating Image Descriptions</div>
            <div class="pubd">We present a model that generates natural language descriptions of full images and their regions. For generating sentences about a given image region we describe a Multimodal Recurrent Neural Network architecture. For inferring the latent alignments between segments of sentences and regions of images we describe a model based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. This work was also featured in a recent <a href="http://www.nytimes.com/2014/11/18/science/researchers-announce-breakthrough-in-content-recognition-software.html">New York Times article</a>.</div>
            <div class="puba">Andrej Karpathy, Li Fei-Fei</div>
            <div class="pubv">CVPR 2015 (Oral)</div>
            <div class="publ">
              <ul>
                <li><a href="http://cs.stanford.edu/people/karpathy/cvpr2015.pdf">PDF</a></li>
                <li><a href="http://cs.stanford.edu/people/karpathy/deepimagesent/">Project</a></li>
                <li><a href="https://github.com/karpathy/neuraltalk2">Code (Github)</a></li>
                <li><a href="http://cs.stanford.edu/people/karpathy/deepimagesent/rankingdemo">Retrieval demo</a></li>
                <li><a href="http://techtalks.tv/talks/deep-visual-semantic-alignments-for-generating-image-descriptions/61593/">Presentation</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
          <img src="./Andrej Karpathy Academic Website_files/mosaic_sm.jpg">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">ImageNet Large Scale Visual Recognition Challenge</div>
            <div class="pubd">Everything you wanted to know about ILSVRC: data collection, results, trends, current computer vision accuracy, even a stab at computer vision vs. human vision accuracy -- all here! My own contribution to this work were the <a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">human accuracy evaluation experiments</a>.
            </div>
            <div class="puba">Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei</div>
            <div class="pubv">IJCV 2015</div>
            <div class="publ">
              <ul>
                <li><a href="http://arxiv.org/abs/1409.0575">PDF</a></li>
                <li><a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">Blog Post</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
          <img src="./Andrej Karpathy Academic Website_files/fragimg3.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Deep Fragment Embeddings for Bidirectional Image-Sentence Mapping</div>
            <div class="pubd">We train a multi-modal embedding to associate fragments of images (objects) and sentences (noun and verb phrases) with a structured, max-margin objective. Our model enables efficient and interpretible retrieval of images from sentence descriptions (and vice versa).</div>
            <div class="puba">Andrej Karpathy, Armand Joulin, Li Fei-Fei</div>
            <div class="pubv">NIPS 2014</div>
            <div class="publ">
              <ul>
                <li><a href="http://cs.stanford.edu/people/karpathy/nips2014.pdf">PDF</a></li>
                <li><a href="http://cs.stanford.edu/people/karpathy/nips2014_supp.pdf">Supplemental</a></li>
                <li><a href="http://cs.stanford.edu/people/karpathy/defrag/index.html">Code</a></li>
                <li><a href="http://cs.stanford.edu/people/karpathy/defragvis/">Web Demo of Results</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./Andrej Karpathy Academic Website_files/videonets.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Large-Scale Video Classification with Convolutional Neural Networks</div>
            <div class="pubd">We introduce Sports-1M: a dataset of 1.1 million YouTube videos with 487 classes of Sport. This dataset allowed us to train large Convolutional Neural Networks that learn spatio-temporal features from video rather than single, static images.</div>
            <div class="puba">Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul Sukthankar, Li Fei-Fei</div>
            <div class="pubv">CVPR 2014 (Oral)</div>
            <div class="publ">
              <ul>
                <li><a href="http://cs.stanford.edu/people/karpathy/deepvideo/">Project</a></li>
                <li><a href="http://cs.stanford.edu/people/karpathy/deepvideo/deepvideo_cvpr2014.pdf">PDF</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./Andrej Karpathy Academic Website_files/rnn.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Grounded Compositional Semantics for Finding and Describing Images with Sentences</div>
            <div class="pubd"> Our model learns to associate images and sentences in a common 

              We use a Recursive Neural Network to compute representation for sentences and a Convolutional Neural Network for images. We then learn a model that associates images and sentences through a structured, max-margin objective. </div>
            <div class="puba">Richard Socher, Andrej Karpathy, Quoc V. Le, Christopher D. Manning, Andrew Y. Ng</div>
            <div class="pubv">TACL 2013</div>
            <div class="publ">
              <ul>
                <li><a href="http://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf">PDF</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./Andrej Karpathy Academic Website_files/discovernet.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Emergence of Object-Selective Features in Unsupervised Feature Learning</div>
            <div class="pubd">
              We introduce an unsupervised feature learning algorithm that is trained explicitly with k-means for simple cells and a form of agglomerative clustering for complex cells. When trained on a large dataset of YouTube frames, the algorithm automatically discovers semantic concepts, such as faces.
            </div>
            <div class="puba">Adam Coates, Andrej Karpathy, Andrew Ng</div>
            <div class="pubv">NIPS 2012</div>
            <div class="publ">
              <ul>
                <li><a href="http://cs.stanford.edu/people/karpathy/nips2012.pdf">PDF</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="pubwrap" style="border-bottom: none; padding-bottom:0px; margin-bottom:30px;">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./Andrej Karpathy Academic Website_files/quadruped.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Locomotion Skills for Simulated Quadrupeds</div>
            <div class="pubd">We develop an integrated set of gaits and skills for a physics-based simulation of a quadruped. The controllers use a representation based on gait graphs, a dual leg frame model, a flexible spine model, and the extensive use of internal virtual forces applied via the Jacobian transpose.</div>
            <div class="puba">Stelian Coros, Andrej Karpathy, Benjamin Jones, Lionel Reveret, Michiel van de Panne</div>
            <div class="pubv">SIGGRAPH 2011</div>
            <div class="publ">
              <ul>
                <li><a href="http://www.cs.ubc.ca/~van/papers/2011-TOG-quadruped/index.html">Project</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="showmore" id="showmorepubs">
    show more
    </div>

    <div id="morepubs">


      <div class="pubwrap">
        <div class="row">
          <div class="col-md-6">
            <div class="pubimg">
              <img src="./Andrej Karpathy Academic Website_files/discovery.jpg">
            </div>
          </div>
          <div class="col-md-6">
            <div class="pub">
              <div class="pubt">Object Discovery in 3D scenes via Shape Analysis</div>
              <div class="pubd">Wouldn't it be great if our robots could drive around our environments and autonomously discovered and learned about objects? In this work we introduce a simple object discovery method that takes as input a scene mesh and outputs a ranked set of segments of the mesh that are likely to constitute objects.</div>
              <div class="puba">Andrej Karpathy, Stephen Miller, Li Fei-Fei</div>
              <div class="pubv">ICRA 2013</div>
              <div class="publ">
                <ul>
                  <li><a href="http://cs.stanford.edu/~karpathy/discovery/">PDF, Code, Data</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="pubwrap" style="border-bottom: none;">
        <div class="row">
          <div class="col-md-6">
            <div class="pubimg">
              <img src="./Andrej Karpathy Academic Website_files/curriculum.png">
            </div>
          </div>
          <div class="col-md-6">
            <div class="pub">
              <div class="pubt">Curriculum Learning for Motor Skills </div>
              <div class="pubd">
                My UBC Master's thesis project. My work was on curriculum learning for motor skills. In particular, I was working with a heavily underactuated (single joint) footed acrobot. The acrobot used a devised curriculum to learn a large variety of parameterized motor skill policies, skill connectivites, and also hierarchical skills that depended on previously acquired skills. Almost all of it from scratch. The project was heavily influenced by intuitions about human development and learning (i.e. trial and error learning, the idea of gradually building skill competencies). The ideas in this work were good, but at the time I wasn't savvy enough to formulate them in a mathematically elaborate way. The video is a fun watch!
              </div>
              <div class="puba">Andrej Karpathy, Michiel van de Panne</div>
              <div class="pubv">AI 2012</div>
              <div class="publ">
                <ul>
                  <li><a href="http://www.cs.ubc.ca/~van/papers/2012-AI-curriculum/index.html">Project</a></li>
                  <li><a href="http://www.cs.ubc.ca/~van/papers/2012-AI-curriculum/2012-AI-curriculum.pdf">PDF</a></li>
                  <li><a href="http://vimeo.com/24446828">Video</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>


  </div>


<hr class="soft">

<div class="container">
  <h2>Teaching</h2>
  <div class="ctr">
    <div class="hht">
      Winter 2015/2016: I was an intructor for <a href="http://vision.stanford.edu/teaching/cs231n/">CS231n: Convolutional Neural Networks for Visual Recognition</a>.
    </div>
    <a href="http://vision.stanford.edu/teaching/cs231n/">
      <img src="./Andrej Karpathy Academic Website_files/cs231n_class.jpg" style="max-width:100%;border-radius:3px;">
    </a>

  <div class="hht">
    <br>
    Have a look at the <a href="http://cs231n.github.io/">class notes</a>, the lecture slides on the <a href="http://cs231n.stanford.edu/syllabus.html">course syllabus page</a>, and on reddit <a href="https://www.reddit.com/r/cs231n">r/cs231n</a>. The lecture videos were available, but had to be <a href="https://www.reddit.com/r/MachineLearning/comments/4hqwza/andrej_karpathy_forced_to_take_down_stanford/">taken down</a> (we're working to bring them back).
  </div>

  </div>
  
</div>

<hr class="soft">

<div class="container">
  <h2>Talks</h2>
  <div class="row">
    <div>Teaching</div>
    <div class="ts">Bay Area Deep Learning School: Convolutional Neural Networks</div>
      <a href="https://www.youtube.com/watch?v=u6aEYuemt0M" target="_blank"><img src="./Andrej Karpathy Academic Website_files/convlecture.png" style="width:100%;border-radius:3px;"></a><br>
    <br><br>
  </div>
  <div class="row">
    <div class="col-md-4">
      <div class="ts">CVPR 2016 Deep Learning Workshop</div>
      <a href="https://www.youtube.com/watch?v=CYwK8bQprBY" target="_blank"><img src="./Andrej Karpathy Academic Website_files/cvpr2016_talk.jpg" style="width:100%;border-radius:3px;"></a><br>
    </div>
    <div class="col-md-4">
      <div class="ts">CVPR 2015 Oral</div>
      <a href="http://techtalks.tv/talks/deep-visual-semantic-alignments-for-generating-image-descriptions/61593/" target="_blank"><img src="./Andrej Karpathy Academic Website_files/cvpr2015_talk.jpeg" style="width:100%;border-radius:3px;"></a><br>
    </div>
   <div class="col-md-4">
      <div class="ts">RE•WORK Deep Learning Summit 2016</div>
      <a href="https://www.youtube.com/watch?v=qPcCk1V1JO8" target="_blank"><img src="./Andrej Karpathy Academic Website_files/rework_talk.jpeg" style="width:100%;border-radius:3px;"></a><br>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-6">
      <div>Academic</div>
       <div class="ts"><a href="http://svg.dmi.unict.it/icvss2016/">ICVSS 2016 Summer School Keynote Invited Speaker</a></div>
      <div class="ts"><a href="http://www.deep-vision.net/">Deep Vision Workshop at CVPR 2016</a></div>
      <div class="ts"><a href="https://www.eecs.mit.edu/news-events/calendar/events/eecs-special-seminar-andrej-karpathy-connecting-images-and-natural">MIT EECS Special Seminar: Andrej Karpathy "Connecting Images and Natural Language"</a></div>
      <div class="ts"><a href="https://www.cs.princeton.edu/events/25394">Princeton CS Department Colloquium: "Connecting Images and Natural Language"</a></div>
      <div class="ts"><a href="http://www.deep-vision.net/">Deep Vision Workshop at CVPR 2015</a></div>
      <div class="ts"><a href="https://www.youtube.com/watch?v=yk6XDFm3J2c">Language &amp; Vision Workshop 2015</a></div>
      <div class="ts"><a href="https://vimeo.com/101555393">Bay Area Multimedia Forum: Large-scale Video Classification with CNNs</a></div>
      <div class="ts"><a href="http://techtalks.tv/talks/large-scale-video-classification-with-convolutional-neural-networks-2/60272/">CVPR 2014 Oral: Large-scale Video Classification with Convolutional Neural Networks</a></div>
      <div class="ts"><a href="http://techtalks.tv/talks/object-discovery-in-3d-scenes-via-shape-analysis/58848/">ICRA 2014: Object Discovery in 3D Scenes Via Shape Analysis</a></div>
    </div>
    <div class="col-md-6">
      <div>On a side</div>
      <div class="ts"><a href="http://www.eventbrite.com/e/stanford-university-nvidia-tech-talks-and-hands-on-labs-tickets-18729102249?aff=Stanford">Stanford University and NVIDIA Tech Talks and Hands-on Labs</a></div>
      <div class="ts"><a href="http://www.meetup.com/sfmachinelearning/events/219842815/">SF ML meetup: Automated Image Captioning with ConvNets and Recurrent Nets</a></div>
      <div class="ts"><a href="https://www.robots.ox.ac.uk/seminars/previousseminars.html">Oxford Robotics Research Group Seminar</a></div>
      <div class="ts"><a href="http://cs.stanford.edu/people/karpathy/">Imperial College London Seminar</a></div>
      <div class="ts"><a href="http://cs.stanford.edu/people/karpathy/">Cambridge Computer Science Seminar</a></div>
      <div class="ts"><a href="http://www.meetup.com/London-Machine-Learning-Meetup/events/224514964/">London Machine Learning Meetup</a></div>
      <div class="ts"><a href="http://www.meetup.com/Data-Science-London/events/224712911/">London Data Science Meetup</a></div>
      <div class="ts"><a href="http://www.meetup.com/Deep-Learning-London/events/224948095/">London Deep Learning Meetup</a></div>
      <div class="ts"><a href="https://www.youtube.com/watch?v=8AnV7xAvpLQ&amp;feature=youtu.be&amp;t=4m15s">NVIDIA GTC 2015 Keynote</a></div>
    </div>
  </div>
  <br><br>
</div>

<hr class="soft">

<div class="container">
  <h2>Pet Projects</h2>
  <div class="row">

    <div class="col-md-4">
      <div class="pp">
        <a href="http://www.arxiv-sanity.com/">
          <img src="./Andrej Karpathy Academic Website_files/sanity.jpeg" class="imgb">
        </a>
        <div class="ppt">Arxiv Sanity Preserver</div>
        <div class="ppd">
        There are way too many Arxiv papers. This project is an attempt to make them searchable and sortable in the pretty interface. The <i>sort by tfidf similarity</i> feature works very well and can be quite useful. My aim is to expand on this project over time, e.g. add a social layer, or create custom paper classifiers / notifications, etc.
        </div>
      </div>
    </div>

    <div class="col-md-4">
      <div class="pp">
        <a href="http://cs.stanford.edu/people/karpathy/convnetjs/">
        <img src="./Andrej Karpathy Academic Website_files/convnetlogo3.png" class="imgb">
        </a>
        <div class="ppt">ConvNetJS</div>
        <div class="ppd">
          ConvNetJS is Deep Learning / Neural Networks library written entirely in Javascript. This enables nice web-based demos that train Convolutional Neural Networks (or ordinary ones) entirely in the browser. Many web demos included. I did an interview with Data Science Weekly about the library and some of its back story <a href="http://www.datascienceweekly.org/data-scientist-interviews/training-deep-learning-models-browser-andrej-karpathy-interview">here</a>.
        </div>
        
      </div>
    </div>
    <div class="col-md-4">
      <div class="pp">
        <a href="http://cs.stanford.edu/people/karpathy/reinforcejs/">
          <img src="./Andrej Karpathy Academic Website_files/mdpdp.jpeg" class="imgb">
        </a>
        <div class="ppt">REINFORCEjs</div>
        <div class="ppd">
           <a href="http://cs.stanford.edu/people/karpathy/reinforcejs/">REINFORCEjs</a> is a Reinforcement Learning library that implements several common RL algorithms supported with fun web demos. The library includes DP,TD,DQN algorithms and sketches of stochastic/deterministic Policy Gradients.
        </div>
      </div>
    </div>

  </div>

  <div class="showmore" id="showmoreprojects">
    show more
  </div>

  <div id="moreprojects">
    <div class="row">
      <div class="col-md-3">
        <div class="pp">
          <a href="https://github.com/karpathy/ulogme">
            <img src="./Andrej Karpathy Academic Website_files/ulogme-small.jpeg" class="imgsm">
          </a>
          <div class="ppt">ulogme</div>
          <div class="ppd">
             ulogme tracks your active windows / keystroke frequencies / notes throughout the entire day and visualizes the results in beautiful d3js timelines. Check out my <a href="http://karpathy.github.io/2014/08/03/quantifying-productivity/">blog post introducing the project</a> to learn more.
          </div>
        </div>
      </div>
      <div class="col-md-3">
        <div class="pp">
          <a href="http://cs.stanford.edu/people/karpathy/nipspreview/">
            <img src="./Andrej Karpathy Academic Website_files/prettypapers.jpg" class="imgsm">
          </a>
          <div class="ppt">Pretty Accepted Papers</div>
          <div class="ppd">
            I was dissatisfied with the format that conferences use to announce the list of accepted papers (e.g. NIPS2012 <a href="http://papers.nips.cc/book/advances-in-neural-information-processing-systems-25-2012">here</a>). This led me to process the page into a <a href="http://cs.stanford.edu/people/karpathy/nipspreview/">much nicer and functional form</a>, with LDA topic analysis etc. The page became quite popular so I continued to make it for <a href="http://cs.stanford.edu/people/karpathy/nips2013/">NIPS 2013</a>, <a href="http://cs.stanford.edu/people/karpathy/cvpr2014papers/">CVPR 2014</a>, <a href="http://cs.stanford.edu/people/karpathy/nips2014/">NIPS2014</a>, <a href="http://cs.stanford.edu/people/karpathy/nips2015/">NIPS2015</a>, <a href="http://cs.stanford.edu/people/karpathy/cvpr2015papers/">CVPR 2015</a>. Others have picked up the Github code and adapted it to <a href="http://benhamner.com/icml2013preview/#/">ICML 2013</a> and <a href="http://www.colinlea.com/guides/cvpr2013.html">CVPR 2013</a>.
          </div>
        </div>
      </div>
      <div class="col-md-3">
        <div class="pp">
          <a href="http://cs.stanford.edu/people/karpathy/researchlei/">
            <img src="./Andrej Karpathy Academic Website_files/lei.png" class="imgsm">
          </a>
          <div class="ppt">Research Lei</div>
          <div class="ppd">
          Research Lei is an Academic Papers Management and Discovery System. It helps researchers build, maintain, and explore academic literature more efficiently, in the browser. <span style="color:#900">(deprecated since Microsoft Academic Search API was shut down :( )</span>
          </div>
        </div>
      </div>
      <div class="col-md-3">
      <div class="pp">
        <a href="http://bit.ly/scholaroctopus">
          <img src="./Andrej Karpathy Academic Website_files/scholaroctopus.jpg" class="imgsm">
        </a>
        <div class="ppt">ScholarOctopus</div>
        <div class="ppd">
          ScholarOctopus takes ~7000 papers from 34 ML/CV conferences (CVPR / NIPS / ICML / ICCV / ECCV / ICLR / BMVC) between 2006 and 2014 and visualizes them with t-SNE based on bigram tfidf vectors. In general, it should be much easier than it currently is to explore the academic literature, find related papers, etc. This hack is a small step in that direction at least for my bubble of related research.
        </div>
      </div>
    </div>
    </div>
    <div class="row">
      <div class="col-md-3">
        <div class="pp">
          <a href="http://cs.stanford.edu/~karpathy/tsnejs/">
            <img src="./Andrej Karpathy Academic Website_files/tsnejslogo.jpg" class="imgsm">
          </a>
          <div class="ppt">tsnejs</div>
          <div class="ppd">
          tsnejs is a t-SNE visualization algorithm implementation in Javascript. I also computed an embedding for ImageNet validation images <a href="http://cs.stanford.edu/people/karpathy/cnnembed/">here</a>. Pretty! You can also use tsnejs to embed (almost) arbitrary CSV data in this <a href="http://cs.stanford.edu/people/karpathy/tsnejs/csvdemo.html">web interface</a>.
          </div>
        </div>
      </div>
      <div class="col-md-3">
        <div class="pp">
          <a href="http://badmephisto.com/iphone/">
            <img src="./Andrej Karpathy Academic Website_files/iphonepad.jpg" class="imgsm">
          </a>
          <div class="ppt">iOS apps</div>
          <div class="ppd">
            I'we written an <a href="http://badmephisto.com/iphone/">iOS app</a> that helps people access and remember Rubik's Cube algorithms. I've later also ported it to Android. There's also my little humble 2-4 player iPad game called <a href="http://itunes.apple.com/us/app/loud-snakes/id523479541?mt=8">Loud Snakes</a> :)
        </div>
        </div>
      </div>
      <div class="col-md-3">
        <div class="pp">
          <a href="http://cs.stanford.edu/people/karpathy/glass/">
            <img src="./Andrej Karpathy Academic Website_files/glass.jpg" class="imgsm">
          </a>
          <div class="ppt">Glass Winners</div>
          <div class="ppd">
            This page was a fun hack. Google was inviting people to become Glass explorers through Twitter (#ifihadclass) and I set out to document the winners of the mysterious process for fun. I didn't expect that it would go on to explode on internet and get me mentions in <a href="http://techcrunch.com/2013/03/31/glass-explorer-apps/">TechCrunch</a>, Verge, and many other places.
          </div>
        </div>
      </div>
      <div class="col-md-3">
        <div class="pp">
          <a href="https://www.youtube.com/watch?v=mSaO0Ul_55c">
            <img src="./Andrej Karpathy Academic Website_files/tetris.jpg" class="imgsm">
          </a>
          <div class="ppt">Tetris AI</div>
          <div class="ppd">
            I think I enjoy writing AIs for games more than I like playing games myself - Over the years I wrote several for World of Warcraft, Farmville, Chess, and <a href="https://www.youtube.com/watch?v=mSaO0Ul_55c">Tetris</a>. On somewhat related note, I also wrote a super-fun <a href="http://code.google.com/p/nplayertetris/">Multiplayer Co-op Tetris</a>.
          </div>
        </div>
      </div>
      
    </div>
    <div class="row">
      <div class="col-md-3">
        <div class="pp">
          <a href="http://cs.stanford.edu/people/karpathy/evenmore.html">
            <img src="./Andrej Karpathy Academic Website_files/circle.svg" class="imgsm">
          </a>
          <div class="ppt">even more</div>
          <div class="ppd">
            Even more various crappy projects I've worked on long time ago.
          </div>
        </div>
      </div>
    </div>
  </div>

</div>

<hr class="soft">

<div class="container">

  <h2>Misc</h2>
  <div class="row">
    <div class="col-md-6">

      <div class="miscitem">
        <div class="miscimg">
          <img src="./Andrej Karpathy Academic Website_files/feed.png" class="img-circle">
        </div>
        <div class="miscd">
          My (mostly) <a href="http://karpathy.github.io/">Academic Blog</a>. I wish all researchers had one.
        </div>
      </div>

      <div class="miscitem">
        <div class="miscimg">
          <img src="./Andrej Karpathy Academic Website_files/circuit.png" class="img-circle">
        </div>
        <div class="miscd">
          <a href="http://karpathy.github.io/neuralnets/">Hacker's Guide to Neural Networks</a> is my attempt at explaining Neural Nets from "Hacker's perspective", relying more on code and physical intuitions than mathematics. I wrote this because I felt there were many people (e.g. some software engineers) who were interested in Deep Nets but who lacked the mathematical background to learn the basics through the usual channels.
        </div>
      </div>

      <div class="miscitem">
        <div class="miscimg">
          <div class="colorrect img-circle"></div>
        </div>
        <div class="miscd">
          I helped create the Programming Assignments for Andrew Ng's <a href="http://www.ml-class.org/">CS229A (Machine Learning Online Class)</a> - this was the precursor to Coursera. At UBC I also TA'd <a href="http://www.cs.ubc.ca/~nando/540-2011/index.php">CPSC540</a> (Graduate Probabilistic Machine Learning) and three times UBC's <a href="http://www.ugrad.cs.ubc.ca/~cs121/current/Homepage/">CPSC 121</a> (Discrete Mathematics), where I taught at tutorials.
        </div>
      </div>

      <div class="miscitem">
        <div class="miscimg">
          <div class="colorrect img-circle"></div>
        </div>
        <div class="miscd">
          I like to go through classes on Coursera and Udacity. I usually look for courses that are taught by very good instructor on topics I know relatively little about. Last year I decided to also finish Genetics and Evolution (<a href="http://cs.stanford.edu/people/karpathy/geneticsacc.jpg">statement of accomplishmnet</a>) and Epigenetics (<a href="http://cs.stanford.edu/people/karpathy/epigenetics_cert.jpg">statement</a>, + <a href="http://cs.stanford.edu/people/karpathy/EpigeneticsCourseranotes.pdf">my rough notes</a>).
        </div>
      </div>


    </div>
    <div class="col-md-6">

      <div class="miscitem">
        <div class="miscimg">
          <img src="./Andrej Karpathy Academic Website_files/twitterblue.svg" class="img-circle">
        </div>
        <div class="miscd">
          Find me on <a href="http://twitter.com/#!/karpathy">Twitter</a>, <a href="https://github.com/karpathy">Github</a>, <a href="https://plus.google.com/100209651993563042175">Google+</a>, <a href="http://www.goodreads.com/user/show/13472185-andrej-karpathy">Goodreads</a>.
        </div>
      </div>

      <div class="miscitem">
        <div class="miscimg">
          <img src="./Andrej Karpathy Academic Website_files/cubevid.jpg" class="img-circle">
        </div>
        <div class="miscd">
          A long time ago I was really into Rubik's Cubes. I learned to solve them in about 17 seconds and then, frustrated by lack of learning resources, created <a href="https://www.youtube.com/user/badmephisto/featured">YouTube videos</a> explaining the Speedcubing methods. These went on to become quite popular. There's also my cubing page <a href="http://badmephisto.com/">badmephisto.com</a>. Oh, and a video of me at a <a href="http://www.facebook.com/photo.php?v=715094857292&amp;set=vb.28120513&amp;type=2&amp;theater">Rubik's cube competition</a> :)
        </div>
      </div>

      <div class="miscitem">
        <div class="miscimg">
          <div class="colorrect img-circle"></div>
        </div>
        <div class="miscd">
          <a href="http://cs.stanford.edu/people/karpathy/advice.html">Advice</a> for doing well in undergrad classes, for younglings.
        </div>
      </div>

      <div class="miscitem">
        <div class="miscd">
          <b>In media:</b><br>
					<div>
					- NVIDIA donating a DGX-1 to OpenAI. <a href="https://blogs.nvidia.com/blog/2016/08/15/first-ai-supercomputer-openai-elon-musk-deep-learning/">Official post</a>, and <a href="http://www.tomshardware.com/news/openai-nvidia-dgx-1-ai-supercomputer,32476.html">one more</a>.
					</div>
          <div>
          - The New York Times article on using deep networks for <a href="http://www.nytimes.com/2014/11/18/science/researchers-announce-breakthrough-in-content-recognition-software.html?_r=0">automatically captioning images with sentences</a>.
          </div>
					<div>
					- <a href="https://www.technologyreview.com/s/600997/hot-commodity/">MIT Technology Review profile</a>
					</div>

          <div>
          - <a href="http://www.economist.com/news/briefing/21650526-artificial-intelligence-scares-peopleexcessively-so-rise-machines">The Economist: Rise of the machines</a>
          </div>

          <div>
          - Wired article on my efforts to evaluate <a href="http://www.wired.com/2015/01/karpathy/">human accuracy on ImageNet</a>
          </div>
          <div>
          - Article on char-rnn: <a href="http://www.engadget.com/2015/12/02/neural-network-journalism-philip-k-dick/">I taught a computer to write like Engadget</a>.
          </div>
          <div>
          - The Verge articles on NeuralTalk, first <a href="http://www.theverge.com/2015/7/17/8985699/stanford-neural-networks-image-recognition-google-study">here</a> and then <a href="http://www.theverge.com/2015/11/25/9798448/neural-network-describe-live-video-neuraltalk">here</a>. Several inaccuracies, but by now quite used to it.
          </div>
					<div>
					- <a href="https://www.quora.com/session/Andrej-Karpathy/1">Quora Session on Sept 8, 2016</a>
       
        </div>
      </div>

    </div>
  </div>

  <div id="misc">
    <div>Still more unsorted misc</div>
    <div class="umisc">- I create those conference proceedings LDA visualization from time to time (<a href="http://cs.stanford.edu/people/karpathy/nips2015/">NIPS 2015 example</a>)</div>
    <div class="umisc">- <a href="http://cs.stanford.edu/people/karpathy/cnnembed/">t-SNE visualization of CNN codes for ImageNet images</a></div>
    <div class="umisc">- an efficient, <a href="https://gist.github.com/karpathy/587454dc0146a6ae21fc">batched Python/numpy implementation</a> of an LSTM forward and backward pass.
    </div>
    <div class="umisc">- a <a href="https://gist.github.com/karpathy/d4dee566867f8291f086"> Minimal character-level Recurrent Neural Network language model</a>, writted in Python/numpy. About 100 lines suffice! :)
    </div>
		<div class="umisc">- <a href="http://lossfunctions.tumblr.com/">Loss Functions Tumblr</a></div>
    <div class="umisc">- <a href="http://cs.stanford.edu/people/karpathy/gan/">Generative Adversarial Nets Javascript demo</a></div>
    <div class="umisc">- <a href="https://medium.com/@karpathy">Medium blog</a></div>

  </div>

  
<!--   <div class="row">
    <div class="col-md-4">
      <div class="pp">
        <img src="./Andrej Karpathy Academic Website_files/cubevid.jpg" class="img-circle imgb">
        <div class="ppt">Rubik's Cube Tutorials</div>
      </div>
    </div>
    <div class="col-md-4">
      <div class="pp">
        <img src="./Andrej Karpathy Academic Website_files/octocat.svg" class="img-circle imgb">
        <div class="ppt">Github</div>
      </div>
    </div>
    <div class="col-md-4">
      <div class="pp">
        <img src="./Andrej Karpathy Academic Website_files/feed.png" class="imgb">
        <div class="ppt">Academic Blog</div>
      </div>
    </div>
  </div>
  
</div> -->

<div id="sitefooter">

</div>

<!-- place js at end for faster loading -->
<script src="./Andrej Karpathy Academic Website_files/jquery-1.11.1.min.js"></script>
<script src="./Andrej Karpathy Academic Website_files/bootstrap.min.js"></script>
<script>

var more_projects_shown = false;
function start() {
  $("#showmoreprojects").click(function() {
    if(!more_projects_shown) {
      $("#moreprojects").slideDown('fast', function() {
        $("#showmoreprojects").text('hide');
      });
      more_projects_shown = true;
    } else {
      $("#moreprojects").slideUp('fast', function() {
        $("#showmoreprojects").text('show more');
      });
      more_projects_shown = false;
    }
  });

  var more_pubs_shown = false;
  $("#showmorepubs").click(function() {
    if(!more_pubs_shown) {
      $("#morepubs").slideDown('fast', function() {
        $("#showmorepubs").text('hide');
      });
      more_pubs_shown = true;
    } else {
      $("#morepubs").slideUp('fast', function() {
        $("#showmorepubs").text('show more');
      });
      more_pubs_shown = false;
    }
  });

}

</script>



</div></body></html>